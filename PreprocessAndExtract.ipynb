{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-ecef85fd4824>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-ecef85fd4824>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    from \"functions\" import *\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline\n",
    "\n",
    "#remember to do \"conda activate mne\" before launching the jupyter notebook\n",
    "from functools import partial\n",
    "#from scipy import signal\n",
    "\n",
    "import h5py\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "#import mne\n",
    "from functions import *\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "datasetPart = 1\n",
    "prePath = \"/Users/tinaraissi/workspace/EEG/tuh-eeg-auto-diagnosis/\"\n",
    "rootdir = {1: prePath+\"v1.4.0_1/edf/train/02_tcp_le/\", 2: prePath+\"v1.4.0_2/edf/train/03_tcp_ar_a/\"}\n",
    "\n",
    "segLabelFilenames = {}\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir[datasetPart]):\n",
    "    for file in files:\n",
    "        p = os.path.join(subdir, file)\n",
    "        if p.endswith(\"edf\"):\n",
    "            segLabelFilenames[p[56:-4]] = p.split(\".edf\")[0]\n",
    "            \n",
    "            \n",
    "#------------------------------------------------------------------------------\n",
    "#Wanted Channels\n",
    "\n",
    "wanted_elecs = ['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1',\n",
    "                'FP2', 'FZ', 'O1', 'O2',\n",
    "                'P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "\n",
    "labels = {'bckg': 1 ,'fnsz': 2,'gnsz': 3,'spsz': 4,'cpsz': 5,'absz':6,'tnsz': 7,'tcsz': 8,'mysz': 9}\n",
    "\n",
    "\n",
    "WINDOWS = [\n",
    "    'barthann',\n",
    "    'bartlett',\n",
    "    'blackman',\n",
    "    'blackmanharris',\n",
    "    'bohman',\n",
    "    'boxcar',\n",
    "    'cosine',\n",
    "    'flattop',\n",
    "    'hamming',\n",
    "    'hann',\n",
    "    'nuttall',\n",
    "    'parzen',\n",
    "    'triang'\n",
    "]\n",
    "\n",
    "time_threshold=100\n",
    "start_time_shift=0.05\n",
    "end_time_shift=0.05\n",
    "power_line_frequency=60\n",
    "low_cut=.2\n",
    "high_cut=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'posixpath' from '/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/posixpath.pyc'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_start_end_artifacts(segment):\n",
    "    \"\"\" Removes self.start_time_shift percent of the recording from the beginning and self.end_time_shift from the\n",
    "    end, since these parts often showed artifacts. \"\"\"\n",
    "\n",
    "    new_start_time_shift = int(start_time_shift * segment.duration)\n",
    "    new_end_time_shift = int(end_time_shift * segment.duration)\n",
    "\n",
    "\n",
    "    segment.signals = segment.signals[:, new_start_time_shift * segment.sampling_freq : -new_end_time_shift * segment.sampling_freq]\n",
    "    segment.duration = segment.duration - (new_start_time_shift + new_end_time_shift)\n",
    "\n",
    "    return segment\n",
    "\n",
    "def filter_power_line_frequency(segment):\n",
    "    \"\"\" Remove the power line frequency from the recordings \"\"\"\n",
    "    segment.signals = mne.filter.notch_filter(segment.signals,\n",
    "                                              segment.sampling_freq,\n",
    "                                              np.arange(power_line_frequency,\n",
    "                                                        segment.sampling_freq/2,\n",
    "                                                        power_line_frequency),\n",
    "                                              verbose='error')\n",
    "    return segment\n",
    "def bandpass_time_domain(segment):\n",
    "    \"\"\" filters the signal to frequency range self.low_cut - self.high_cut \"\"\"\n",
    "    segment.signals = mne.filter.filter_data(segment.signals,\n",
    "                                             segment.sampling_freq,\n",
    "                                             low_cut,\n",
    "                                             high_cut,\n",
    "                                             verbose='error')\n",
    "    return segment\n",
    "def volts_to_microvolts(segment):\n",
    "    segment.signals *= 1000000\n",
    "    return segment\n",
    "\n",
    "def clean(segment):\n",
    "    #segment = remove_start_end_artifacts(segment)\n",
    "    segment = filter_power_line_frequency(segment)\n",
    "    # TODO: this seems to \"recenter\" the data! find out why and how\n",
    "    segment = bandpass_time_domain(segment)\n",
    "\n",
    "    # drastically reduce amount of data by grabbing 1 minute of recording from the middle\n",
    "    # rec = self.cut_one_minute(rec)\n",
    "\n",
    "    # transform signal amplitudes from volts to microvolts\n",
    "    segment = volts_to_microvolts(segment)\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSplitter(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "# ______________________________________________________________________________________________________________________\n",
    "    def get_supported_windows():\n",
    "        return WINDOWS\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________________________________________________\n",
    "    def windows_weighted(self, windows, window_size):\n",
    "        \"\"\" weights the splitted signal by the specified window function\n",
    "        :param windows: the signals splitted into time windows\n",
    "        :param window_size: the number of samples in the window\n",
    "        :return: the windows weighted by the specified window function\n",
    "        \"\"\"\n",
    "        method_to_call = getattr(signal, self.window)\n",
    "        window = method_to_call(window_size)\n",
    "\n",
    "        return windows * window\n",
    "\n",
    "# ______________________________________________________________________________________________________________________\n",
    "    def split(self, rec):\n",
    "        \"\"\" written by robin schirrmeister, adapted by lukas gemein\n",
    "        :param rec: the recording object holding the signals and all information needed\n",
    "        :return: the signals split into time windows of the specified size\n",
    "        \"\"\"\n",
    "        window_size = int(rec.sampling_freq * self.window_size_sec)\n",
    "        overlap_size = int(self.overlap * window_size)\n",
    "        stride = window_size - overlap_size\n",
    "\n",
    "        if stride == 0:\n",
    "            logging.error(\"Time windows cannot have an overlap of 100%.\")\n",
    "\n",
    "        # written by robin tibor schirrmeister\n",
    "        signal_crops = []\n",
    "        for i_start in range(0, rec.signals.shape[-1] - window_size + 1, stride):\n",
    "            signal_crops.append(np.take(rec.signals, range(i_start, i_start + window_size), axis=-1, ))\n",
    "\n",
    "        return self.windows_weighted(np.array(signal_crops), window_size)\n",
    "\n",
    "# ______________________________________________________________________________________________________________________\n",
    "    def __init__(self, overlap=50, window='boxcar', window_size_sec=2):\n",
    "        self.overlap = overlap/100\n",
    "        self.window = window\n",
    "        self.window_size_sec = window_size_sec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Recording(object):\n",
    "    \"\"\" This is a container class for all the relevant data of a EEG recording\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_set, edf_file_path, raw_edf, sampling_freq, n_samples, n_signals, signal_names, duration,\n",
    "                 label_info_list, signals=None, signals_complete=None, signals_ft=None):\n",
    "        self.data_set = data_set\n",
    "        self.edf_file_path = edf_file_path\n",
    "        self.raw_edf = raw_edf\n",
    "        self.sampling_freq = sampling_freq\n",
    "        self.n_samples = n_samples\n",
    "        self.n_signals = n_signals\n",
    "        self.signal_names = signal_names\n",
    "        self.duration = duration\n",
    "        self.signals = signals\n",
    "        self.signal_ft = signals_ft\n",
    "        self.signals_complete = signals_complete\n",
    "        self.label_info_list = label_info_list\n",
    "\n",
    "        \n",
    "    def init_processing_units(self):\n",
    "        self.splitter = DataSplitter(overlap = 50, window_size_sec=2)\n",
    "        #self.feature_generator = feature_generator.FeatureGenerator(domain=cmd_args.domain, bands=cmd_args.bands,\n",
    "        #                                                            window_size_sec=2,\n",
    "        #                                                            overlap=50,\n",
    "        #                                                           electrodes=wanted_elecs)\n",
    "        \n",
    "        \n",
    "class Segment(object):\n",
    "    \n",
    "    def __init__(self, sampling_freq, n_samples, signal_names, duration, label,\n",
    "                 signals, signals_ft=None):\n",
    "\n",
    "        self.sampling_freq = sampling_freq\n",
    "        self.n_samples = n_samples\n",
    "        self.signal_names = signal_names\n",
    "        self.duration = duration\n",
    "        self.signals = signals\n",
    "        self.label= label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWantedChannelsFromRecording(rec_channels, wanted_elecs):\n",
    "    \n",
    "    selected_ch_names = []\n",
    "    for wanted_part in wanted_elecs:\n",
    "        wanted_found_name = []\n",
    "        for ch_name in rec_channels:\n",
    "            if ' ' + wanted_part + '-' in ch_name:\n",
    "                wanted_found_name.append(ch_name)\n",
    "        assert len(wanted_found_name) == 1\n",
    "        selected_ch_names.append(wanted_found_name[0])\n",
    "    return selected_ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_segmet_with_label_from_recording(rec):\n",
    "    segments = []\n",
    "    for l in rec.label_info_list:\n",
    "        startTime = float(l[0])\n",
    "        endTime = float(l[1])\n",
    "        startIndex = int(startTime*rec.sampling_freq)\n",
    "        endIndex = int(endTime*rec.sampling_freq)\n",
    "        label = int(l[2])\n",
    "        duration = round(endTime - startTime, 4)\n",
    "        n_samples = duration * rec.sampling_freq\n",
    "        signals = rec.signals[:,startIndex:endIndex]\n",
    "        s = Segment(rec.sampling_freq, n_samples, rec.signal_names, duration, label, signals)\n",
    "        segments.append(s)\n",
    "    return segments\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabelAndTimeStartAndEnd(filename):\n",
    "    returnList = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            if len(line.split()) == 4:\n",
    "                returnList.append(line.split()[:-1])\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recording_with_mne(file_path):\n",
    "    \"\"\" read info from the edf file without loading the data. loading data is done in multiprocessing since it takes\n",
    "    some time. getting info is done before because some files had corrupted headers or weird sampling frequencies\n",
    "    that caused the multiprocessing workers to crash. therefore get and check e.g. sampling frequency and duration\n",
    "    beforehand\n",
    "    :param file_path: path of the recording file\n",
    "    :return: file name, sampling frequency, number of samples, number of signals, signal names, duration of the rec\n",
    "    \"\"\"\n",
    "    \n",
    "    edf_file_path = file_path+\".edf\" \n",
    "    try:\n",
    "        edf_file = mne.io.read_raw_edf(file_path+\".edf\", verbose='error')\n",
    "        labelLists = getLabelAndTimeStartAndEnd(file_path+\".tse\")\n",
    "    except ValueError:\n",
    "        return None, None, None, None, None, None\n",
    "        # fix_header(file_path)\n",
    "        # try:\n",
    "        #     edf_file = mne.io.read_raw_edf(file_path, verbose='error')\n",
    "        #     logging.warning(\"Fixed it!\")\n",
    "        # except ValueError:\n",
    "        #     return None, None, None, None, None, None\n",
    "\n",
    "    # some recordings have a very weird sampling frequency. check twice before skipping the file\n",
    "    sampling_frequency = int(edf_file.info['sfreq'])\n",
    "    if sampling_frequency < 10:\n",
    "        return None\n",
    "        #sampling_frequency = 1 / (edf_file.times[1] - edf_file.times[0])\n",
    "        #if sampling_frequency < 10:\n",
    "        #    return None, sampling_frequency, None, None, None, None\n",
    "    n_samples = edf_file.n_times\n",
    "    signal_names = edf_file.ch_names\n",
    "    n_signals = len(signal_names)\n",
    "    # some weird sampling frequencies are at 1 hz or below, which results in division by zero\n",
    "    duration = n_samples / max(sampling_frequency, 1)\n",
    "    label_info_list = []\n",
    "    for ele in labelLists:\n",
    "        ele[2] = labels[ele[2]]\n",
    "        label_info_list.append(ele)\n",
    "    \n",
    "     \n",
    "    return edf_file_path, edf_file, sampling_frequency, n_samples, n_signals, signal_names, duration, label_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_with_mne_for_electrodes_in_signal_names(rec):\n",
    "    \"\"\" loads the data using the mne library\n",
    "    :param rec: recording object holding all necessary data of an eeg recording\n",
    "    :return: a pandas dataframe holding the data of all electrodes as specified in the rec object\n",
    "    \"\"\"\n",
    "    rec.raw_edf.load_data()\n",
    "    signals = rec.raw_edf.get_data()\n",
    "    wantedChannels = getWantedChannelsFromRecording(rec.signal_names, wanted_elecs)\n",
    "\n",
    "    data = pd.DataFrame(index=range(rec.n_samples), columns=wantedChannels)\n",
    "    for electrode in wantedChannels:\n",
    "        data[electrode] = signals[list(rec.signal_names).index(electrode)]\n",
    "\n",
    "\n",
    "    return data.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_segments():\n",
    "    segmentDicTLabel = dict(zip(list(labels.values()),[[] for _ in range(len((labels.keys())))]))\n",
    "    for index, fName in enumerate(segLabelFilenames.keys()):\n",
    "        print(\"working on recording \", str(index) +\"/\"+ str(len(segLabelFilenames.keys())))\n",
    "        rec = Recording(\"/\", *get_recording_with_mne(segLabelFilenames[fName]))\n",
    "        rec.signals = load_data_with_mne_for_electrodes_in_signal_names(rec)\n",
    "        segs = get_segmet_with_label_from_recording(rec)\n",
    "        for s in segs:\n",
    "            segmentDicTLabel[s.label].append(clean(s))\n",
    "            \n",
    "    return segmentDicTLabel\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nwrite:\\n\\nremember you read it in this way\\n\\nwith h5py.File(\"p.hdf\", \"r\") as f:\\n    a = f[\"data\"]\\n    print(a.attrs[\"sampling_freq\"])\\n    X = a[:]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_hdf5(segmentList, label):\n",
    "    \"\"\" writes features to hdf5 file\n",
    "    :param features: a matrix holding a feature vector for every recordings (maybe someday for every time window of\n",
    "    every recording)\n",
    "    :param in_dir: input directory used to extract the name if the class\n",
    "    :param cmd_args: used to include important information in the file name s.a. window, windowsize etc\n",
    "    :return: the name of the feature file\n",
    "    \"\"\"\n",
    "    for ind, s in enumerate(segmentList):\n",
    "        file_name = \"hdf\"+str(datasetPart)+\"/\"+str(label)+\"/\" + str(ind) + \".hdf\"\n",
    "        if not os.path.exists(file_name):\n",
    "            print(\"writing \"+str(file_name))\n",
    "            hdf5_f= h5py.File(file_name, 'w')\n",
    "            dset = hdf5_f.create_dataset('data', s.signals.shape, data= s.signals)\n",
    "            dset.attrs[\"sampling_freq\"] = s.sampling_freq\n",
    "            dset.attrs[\"channel_names\"] = s.signal_names\n",
    "            dset.attrs[\"duration\"] = s.duration\n",
    "            dset.attrs[\"label\"] = s.label\n",
    "            hdf5_f.close()\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "write:\n",
    "\n",
    "remember you read it in this way\n",
    "\n",
    "with h5py.File(\"p.hdf\", \"r\") as f:\n",
    "    a = f[\"data\"]\n",
    "    print(a.attrs[\"sampling_freq\"])\n",
    "    X = a[:]\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#allSegments = get_all_segments()\n",
    "\n",
    "#for k in allSegments.keys():\n",
    "#    write_hdf5(allSegments[k], str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#experiment on one recording\n",
    "#after this step I have a recording object with signal samples\n",
    "\n",
    "#p = list(segLabelFilenames.keys())[30]\n",
    "#edf_file = mne.io.read_raw_edf(segLabelFilenames[p]+\".edf\", verbose='error')\n",
    "#edf_file.load_data()\n",
    "#data = edf_file.get_data()\n",
    "\n",
    "\n",
    "\n",
    "#p = list(segLabelFilenames.keys())[30]\n",
    "#edfFile = get_info_with_mne(segLabelFilenames[p]+\".edf\")\n",
    "#labelLists = getLabelAndTimeStartAndEnd(segLabelFilenames[p]+\".tse\")\n",
    "#rec = Recording(\"/\", *get_recording_with_mne(segLabelFilenames[p]))\n",
    "#create hdf starting by recording, take the segment of the label, add samples for that segment, \n",
    "#and use other information, like sampling frequency, duration, sex, age, label, channels\n",
    "#rec.signals = load_data_with_mne_for_electrodes_in_signal_names(rec) \n",
    "#cleanedRec = clean(rec)\n",
    "#cleanedRec.init_processing_units()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec.raw_edf.load_data()\n",
    "signals = rec.raw_edf.get_data()\n",
    "\n",
    "data = pd.DataFrame(index=range(rec.n_samples), columns=rec.signal_names)\n",
    "for electrode_id, electrode in enumerate(rec.signal_names):\n",
    "    data[electrode] = signals[electrode_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnPrePAth = \"hdf1/2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(fnPrePAth+\"1.hdf\", \"r\") as f:\n",
    "    a = f[\"data\"]\n",
    "    print(a.attrs[\"sampling_freq\"])\n",
    "    X = a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4530)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
