{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important functions you will need\n",
    "\n",
    "def get_info_with_mne(file_path):\n",
    "    \"\"\" read info from the edf file without loading the data. loading data is done in multiprocessing since it takes\n",
    "    some time. getting info is done before because some files had corrupted headers or weird sampling frequencies\n",
    "    that caused the multiprocessing workers to crash. therefore get and check e.g. sampling frequency and duration\n",
    "    beforehand\n",
    "    :param file_path: path of the recording file\n",
    "    :return: file name, sampling frequency, number of samples, number of signals, signal names, duration of the rec\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edf_file = mne.io.read_raw_edf(file_path, verbose='error')\n",
    "    except ValueError:\n",
    "        return None, None, None, None, None, None\n",
    "        # fix_header(file_path)\n",
    "        # try:\n",
    "        #     edf_file = mne.io.read_raw_edf(file_path, verbose='error')\n",
    "        #     logging.warning(\"Fixed it!\")\n",
    "        # except ValueError:\n",
    "        #     return None, None, None, None, None, None\n",
    "\n",
    "    # some recordings have a very weird sampling frequency. check twice before skipping the file\n",
    "    sampling_frequency = int(edf_file.info['sfreq'])\n",
    "    if sampling_frequency < 10:\n",
    "        sampling_frequency = 1 / (edf_file.times[1] - edf_file.times[0])\n",
    "        if sampling_frequency < 10:\n",
    "            return None, sampling_frequency, None, None, None, None\n",
    "\n",
    "    n_samples = edf_file.n_times\n",
    "    signal_names = edf_file.ch_names\n",
    "    n_signals = len(signal_names)\n",
    "    # some weird sampling frequencies are at 1 hz or below, which results in division by zero\n",
    "    duration = n_samples / max(sampling_frequency, 1)\n",
    "\n",
    "    # TODO: return rec object?\n",
    "    return edf_file, sampling_frequency, n_samples, n_signals, signal_names, duration\n",
    "\n",
    "def preprocess(self, cmd_args):\n",
    "    \"\"\" Checks if all the EEG recordings of the input directories can be processed. For every processable recording\n",
    "    an entry in the multiprocessing queue is inserted. Results (features) are written to .hdf5 files per input dir.\n",
    "    :param cmd_args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    self.init_processing_units(cmd_args)\n",
    "\n",
    "    # create output directory\n",
    "    my_io.check_out(cmd_args.output, cmd_args.input)\n",
    "    my_io.write_feature_labels(cmd_args.output, self.feature_generator.get_feature_labels())\n",
    "\n",
    "    # set up multiprocessing\n",
    "    manager = mp.Manager()\n",
    "    in_q, out_q = manager.Queue(), manager.Queue()\n",
    "\n",
    "    # stores for every class the hdf5 file name where features are stored\n",
    "    feature_files = []\n",
    "    for in_dir_id, in_dir in enumerate(cmd_args.input):\n",
    "        self.check_path(in_dir)\n",
    "        self.stats.n_classes += 1\n",
    "        self.recording_names[in_dir] = list()\n",
    "\n",
    "        edf_files = self.read_files(in_dir, cmd_args.subset)\n",
    "        self.stats.n_recordings += len(edf_files)\n",
    "\n",
    "        in_q, edf_count = self.add_recording_to_queue(in_dir, edf_files, in_q)\n",
    "\n",
    "        self.spawn_start_join_processes(cmd_args, in_q, out_q)\n",
    "\n",
    "        features = self.catch_results(in_dir_id, in_dir, out_q, edf_count)\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        file_name = my_io.write_hdf5(features, in_dir, cmd_args)\n",
    "        feature_files.append(file_name)\n",
    "\n",
    "    # TODO: add this\n",
    "    my_io.write_recording_names(cmd_args.output, cmd_args.input, self.recording_names)\n",
    "\n",
    "    return feature_files, self.window_counts, self.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFromEdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "#remember to do \"conda activate mne\" before launching the jupyter notebook\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import mne\n",
    "\n",
    "prePath = \"/Users/tinaraissi/workspace/EEG/tuh-eeg-auto-diagnosis/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataframe(filename):\n",
    "    #this function read an edf file and returns a dataframe (n_samples * n_channels)\n",
    "    # having the time samples for each electrode in each column\n",
    "    \n",
    "    edfData =  mne.io.read_raw_edf(filename)\n",
    "    dataFromEdf = edfData.get_data()\n",
    "    dataset = pd.DataFrame(index=range(edfData.n_times), columns=edfData.ch_names)\n",
    "\n",
    "    #At this point you have \n",
    "    for dataSample, channel in enumerate(edfData.ch_names):\n",
    "        dataset[channel] = dataFromEdf[dataSample]\n",
    "        \n",
    "    return edfData, dataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/tinaraissi/workspace/EEG/tuh-eeg-auto-diagnosis/v1.4.0/edf/train/02_tcp_le/001/00000143/s001_2003_03_10/00000143_s001_t001.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "#File formats in the relative folder\n",
    "#*.edf:    the EEG sampled data in European Data Format (edf)\n",
    "#*.txt:    the EEG report corresponding to the patient and session\n",
    "#*.tse:    term-based annotations using all available seizure type classes\n",
    "#*.tse_bi: same as *.tse except bi-class annotations (seizure/background) \n",
    "#*.lbl:    event-based annotations using all available seizure type classes\n",
    "#*.lbl_bi: same as *.lbl except bi-class annotations (seizure/background)\n",
    "\n",
    "filename = prePath+\"v1.4.0/edf/train/02_tcp_le/001/00000143/s001_2003_03_10/00000143_s001_t001.edf\"\n",
    "edfData, dataset =  getDataframe(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFilename = prePath+\"v1.4.0/edf/train/02_tcp_le/001/00000143/s001_2003_03_10/00000143_s001_t001.tse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_processing_units():\n",
    "    self.cleaner = data_cleaner.DataCleaner(elecs=cmd_args.elecs)\n",
    "    self.splitter = data_splitter.DataSplitter(window=cmd_args.window, window_size_sec=cmd_args.windowsize,\n",
    "                                               overlap=cmd_args.overlap)\n",
    "    self.feature_generator = feature_generator.FeatureGenerator(domain=cmd_args.domain, bands=cmd_args.bands,\n",
    "                                                                window_size_sec=cmd_args.windowsize,\n",
    "                                                                overlap=cmd_args.overlap, perrec=cmd_args.perrec,\n",
    "                                                                electrodes=self.cleaner.get_electrodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Tinaraissi/Workspace/Eeg/Tuh-Eeg-Auto-Diagnosis/V1.4.0/Edf/Train/02_Tcp_Le/001/00000143/S001_2003_03_10/00000143_S001_T001.Edf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['version', '=', 'tse_v1.0.0']\n",
      "[]\n",
      "['0.0000', '1279.0000', 'bckg', '1.0000']\n"
     ]
    }
   ],
   "source": [
    "with open(labelFilename) as file:\n",
    "    for line in file:\n",
    "        print(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
